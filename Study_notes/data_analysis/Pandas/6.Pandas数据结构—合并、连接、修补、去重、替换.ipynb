{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas数据结构—合并、连接、修补、去重、替换\n",
    "##### 一、合并（一） merge\n",
    "##### 二、合并（二）join\n",
    "##### 三、连接 concat\n",
    "##### 四、修补 combine_first、updata\n",
    "##### 五、去重 duplicated\n",
    "##### 六、替换 replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 一、合并（一）-merge\n",
    "###### merge有点类似vlookup，但是比vlookup更灵活。\n",
    "###### merge的参数有很多：\n",
    "###### left, right, how='inner', on=None, left_on=None, right_on=None,left_index=False, right_index=False, \n",
    "###### sort=True, suffixes=('_x', '_y'), copy=True, indicator=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   A   B\n",
      "0  K0  A0  B0\n",
      "1  K1  A1  B1\n",
      "2  K2  A2  B2\n",
      "3  K3  A3  B3\n",
      "--------------------------------\n",
      "  key   C   D\n",
      "0  K0  C0  D0\n",
      "1  K1  C1  D1\n",
      "2  K2  C2  D2\n",
      "3  K3  C3  D3\n",
      "--------------------------------\n",
      "  key1 key2   A   B\n",
      "0   K0   K0  A0  B0\n",
      "1   K0   K1  A1  B1\n",
      "2   K1   K0  A2  B2\n",
      "3   K2   K1  A3  B3\n",
      "--------------------------------\n",
      "  key1 key2   C   D\n",
      "0   K0   K0  C0  D0\n",
      "1   K1   K0  C1  D1\n",
      "2   K1   K0  C2  D2\n",
      "3   K2   K0  C3  D3\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                     'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "                      'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "df3 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df4 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                    'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "# 可以看到df1和df2都有key这个列，并且数据都相同。\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "# df3和df4都有key1列和key2列，但是有一部分数据不同。\n",
    "print(df3)\n",
    "print('--------------------------------')\n",
    "print(df4)\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1、参数 left 、right、on\n",
    "###### left：准备合并的第一组数据\n",
    "###### right：准备合并的第二组数据\n",
    "###### on：参考键"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将df1和df2进行合并，合并的原则是根据参考键key： \n",
      "   key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n",
      "--------------------------------\n",
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# 通过设置参数on的值来确定合并的参考键。也就说以什么作为参考。on = 'key'就是以key作为参考。\n",
    "print('将df1和df2进行合并，合并的原则是根据参考键key： \\n',pd.merge(df1, df2, on = 'key'))\n",
    "print('--------------------------------')\n",
    "\n",
    "# df3和df4的key1和key2的第一行数据相同，所以进行合并。\n",
    "# df3的key1和key2的第二行数据，在df4的key1和key2列中没有相同的数据，所以不进行合并。\n",
    "# 注意：df3的key1和key2的第三行数据，和df4的key1和key2列中有两行相同的数据，所以会进行两次合并。\n",
    "# # df3的key1和key2的第四行数据，在df4的key1和key2列中没有相同的数据，所以不进行合并。\n",
    "print(pd.merge(df3, df4, on = ['key1','key2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2、参数how\n",
    "###### how：合并方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n",
      "--------------------------------\n",
      "  key1 key2    A    B    C    D\n",
      "0   K0   K0   A0   B0   C0   D0\n",
      "1   K0   K1   A1   B1  NaN  NaN\n",
      "2   K1   K0   A2   B2   C1   D1\n",
      "3   K1   K0   A2   B2   C2   D2\n",
      "4   K2   K1   A3   B3  NaN  NaN\n",
      "5   K2   K0  NaN  NaN   C3   D3\n",
      "--------------------------------\n",
      "  key1 key2   A   B    C    D\n",
      "0   K0   K0  A0  B0   C0   D0\n",
      "1   K0   K1  A1  B1  NaN  NaN\n",
      "2   K1   K0  A2  B2   C1   D1\n",
      "3   K1   K0  A2  B2   C2   D2\n",
      "4   K2   K1  A3  B3  NaN  NaN\n",
      "--------------------------------\n",
      "  key1 key2    A    B   C   D\n",
      "0   K0   K0   A0   B0  C0  D0\n",
      "1   K1   K0   A2   B2  C1  D1\n",
      "2   K1   K0   A2   B2  C2  D2\n",
      "3   K2   K0  NaN  NaN  C3  D3\n"
     ]
    }
   ],
   "source": [
    "# how = 'inner'：表示取的是交集\n",
    "print(pd.merge(df3, df4,on=['key1','key2'], how = 'inner'))  \n",
    "print('--------------------------------')\n",
    "\n",
    "# how = 'outer'：表示取的是并集，如果数据缺失就用NaN填充\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'outer'))  \n",
    "print('--------------------------------')\n",
    "\n",
    "# how = 'left'：表示将第一组准备合并的数据为参考进行合并（本例中是df3），如果数据缺失就用NaN填充\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'left'))  \n",
    "print('--------------------------------')\n",
    "\n",
    "# how = 'right'：表示将第二组准备合并的数据为参考进行合并（本例中是df4），如果数据缺失就用NaN填充\n",
    "print(pd.merge(df3, df4, on=['key1','key2'], how = 'right'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3、参数 left_on, right_on, left_index, right_index \n",
    "###### 当键不同时，可以通过left_on, right_on分别设置左键与右键。当键相同时，直接用on\n",
    "###### 当两组数据的列名不同时可以使用left_index, right_index来进行合并操作。\n",
    "###### left_on, right_on, left_index, right_index可以进行相互的组合：\n",
    "###### left_on + right_on, left_on + right_index, left_index + right_on, left_index + right_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  xkey  data1\n",
      "0    a      0\n",
      "1    b      1\n",
      "2    c      2\n",
      "3    d      3\n",
      "4    e      4\n",
      "5    f      5\n",
      "6    s      6\n",
      "--------------------------------\n",
      "  ykey  date2\n",
      "0    a      0\n",
      "1    b      1\n",
      "2    d      2\n",
      "--------------------------------\n",
      "  xkey  data1 ykey  date2\n",
      "0    a      0    a      0\n",
      "1    b      1    b      1\n",
      "2    d      3    d      2\n",
      "--------------------------------\n",
      "  key  data1\n",
      "0   a      0\n",
      "1   b      1\n",
      "2   c      2\n",
      "3   d      3\n",
      "4   f      4\n",
      "5   e      5\n",
      "6   g      6\n",
      "--------------------------------\n",
      "   data2\n",
      "a     10\n",
      "b     11\n",
      "c     12\n",
      "d     13\n",
      "e     14\n",
      "--------------------------------\n",
      "  key  data1  data2\n",
      "0   a      0     10\n",
      "1   b      1     11\n",
      "2   c      2     12\n",
      "3   d      3     13\n",
      "5   e      5     14\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'xkey':list('abcdefs'),\n",
    "                   'data1':range(7)})\n",
    "df2 = pd.DataFrame({'ykey':list('abd'),\n",
    "                   'date2':range(3)})\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过left_on='xkey', right_on='ykey'分别设置了合并所需的左键和右键。\n",
    "# 在合并的时候，依然会比较这两个键里的具体数据是否有相同的，如果有就进行合并。\n",
    "print(pd.merge(df1, df2, left_on='xkey', right_on='ykey'))\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "df3 = pd.DataFrame({'key':list('abcdfeg'),\n",
    "                   'data1':range(7)})\n",
    "df4 = pd.DataFrame({'data2':range(10,15)},\n",
    "                  index = list('abcde'))\n",
    "print(df3)\n",
    "print('--------------------------------')\n",
    "print(df4)\n",
    "print('--------------------------------')\n",
    "\n",
    "# df3有key和data1两列，df4除了index就只有data2一列，但是index和df3的key有部分相同。\n",
    "# 将df3设置成以‘key’为键，而df4设置成以index为键。\n",
    "# left_index：为True时，第一组数据是以index为键，默认False\n",
    "# right_index：为True时，第二组数据是以index为键，默认False\n",
    "print(pd.merge(df3, df4, left_on='key', right_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4、参数 sort\n",
    "###### 按照字典的顺序对结果进行排序。默认为False，设置为False会大幅提高性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data1\n",
      "0   a      1\n",
      "1   b      3\n",
      "2   c      2\n",
      "3   d      4\n",
      "4   e      5\n",
      "5   f      9\n",
      "6   g      7\n",
      "--------------------------------\n",
      "  key  data2\n",
      "0   a      1\n",
      "1   b      2\n",
      "2   d      3\n",
      "--------------------------------\n",
      "  key  data1  data2\n",
      "0   a      1    1.0\n",
      "1   b      3    2.0\n",
      "2   c      2    NaN\n",
      "3   d      4    3.0\n",
      "4   e      5    NaN\n",
      "5   f      9    NaN\n",
      "6   g      7    NaN\n",
      "--------------------------------\n",
      "  key  data1  data2\n",
      "0   a      1    1.0\n",
      "1   b      3    2.0\n",
      "2   c      2    NaN\n",
      "3   d      4    3.0\n",
      "4   e      5    NaN\n",
      "5   f      9    NaN\n",
      "6   g      7    NaN\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key':list('abcdefg'),\n",
    "                   'data1':[1,3,2,4,5,9,7]})\n",
    "df2 = pd.DataFrame({'key':list('abd'),\n",
    "                   'data2':[1,2,3]})\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 将df1和df2以key为键，进行合并，并且取并集。\n",
    "pm1 = pd.merge(df1,df2, on = 'key', how = 'outer')\n",
    "\n",
    "# 将df1和df2以key为键，进行合并，并且取交集，而且还要进行排序。\n",
    "pm2 = pd.merge(df1,df2, on = 'key', sort=True, how = 'outer')\n",
    "print(pm1)\n",
    "print('--------------------------------')\n",
    "print(pm2)\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 二、合并（二）-join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "--------------------------------\n",
      "     C   D\n",
      "K0  C0  D0\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "--------------------------------\n",
      "     A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n",
      "--------------------------------\n",
      "      A    B    C    D\n",
      "K0   A0   B0   C0   D0\n",
      "K1   A1   B1  NaN  NaN\n",
      "K2   A2   B2   C2   D2\n",
      "K3  NaN  NaN   C3   D3\n",
      "--------------------------------\n",
      "     A   B    D\n",
      "K0  A0  B0   D0\n",
      "K1  A1  B1  NaN\n",
      "K2  A2  B2   D2\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                    index=['K0', 'K1', 'K2'])\n",
    "df2 = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                      'D': ['D0', 'D2', 'D3']},\n",
    "                     index=['K0', 'K2', 'K3'])\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 以index为键将df1和df2进行合并。其中df1是为主，也就是说以df1为准备，然后根据df2进行合并。具体说明如下：\n",
    "# df1的index有'K0', 'K1', 'K2'\n",
    "# df2的index有'K0', 'K2', 'K3'\n",
    "# 因为df1和df2中都'K0'和'K2',所以这两行就直接合并了。而K1因为只在df1中有，所以合并后缺失值用NaN来填充。\n",
    "print(df1.join(df2))\n",
    "print('--------------------------------')\n",
    "\n",
    "# 下面这句等价于：pd.merge(left, right, left_index=True, right_index=True, how='outer')\n",
    "# 注意：因为how='outer'所以取的是交集。也就是说有对应的数据就合并，没有的就用NaN来填充缺失值。\n",
    "print(df1.join(df2, how='outer'))  \n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1、参数suffixes\n",
    "###### 为合并后相同的键进行区分.默认的是('_x', '_y')。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  data1\n",
      "0   a      1\n",
      "1   b      3\n",
      "2   c      2\n",
      "3   d      4\n",
      "4   e      5\n",
      "5   f      9\n",
      "6   g      7\n",
      "--------------------------------\n",
      "  key  data2\n",
      "0   a      1\n",
      "1   b      2\n",
      "2   d      3\n",
      "--------------------------------\n",
      "  key_x  data1 key_y  data2\n",
      "0     a      1     a      1\n",
      "1     b      3     b      2\n",
      "2     c      2     d      3\n",
      "--------------------------------\n",
      "  key_666  data1 key_777  data2\n",
      "0       a      1       a      1\n",
      "1       b      3       b      2\n",
      "2       c      2       d      3\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key':list('abcdefg'),\n",
    "                   'data1':[1,3,2,4,5,9,7]})\n",
    "df2 = pd.DataFrame({'key':list('abd'),\n",
    "                   'data2':[1,2,3]})\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 因为df1和df2中都有key，所以通过suffixes来区分。如果不写suffixes那么就用默认值来区分。\n",
    "print(pd.merge(df1, df2, left_index=True, right_index=True)) \n",
    "print('--------------------------------')\n",
    "# df1的key用key_666，df2的key用key_777\n",
    "print(pd.merge(df1, df2, left_index=True, right_index=True, suffixes=('_666', '_777'))) \n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2、参数on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key\n",
      "0  A0  B0  K0\n",
      "1  A1  B1  K1\n",
      "2  A2  B2  K0\n",
      "3  A3  B3  K1\n",
      "--------------------------------\n",
      "       C     D\n",
      "K0  C666  D666\n",
      "K1  C777  D777\n",
      "--------------------------------\n",
      "    A   B key     C     D\n",
      "0  A0  B0  K0  C666  D666\n",
      "1  A1  B1  K1  C777  D777\n",
      "2  A2  B2  K0  C666  D666\n",
      "3  A3  B3  K1  C777  D777\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                     'key': ['K0', 'K1', 'K0', 'K1']})\n",
    "df2 = pd.DataFrame({'C': ['C666', 'C777'],\n",
    "                      'D': ['D666', 'D777']},\n",
    "                     index=['K0', 'K1'])\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "\n",
    "# join默认是用index作为键，但是可以通过on参数来调整。\n",
    "# df1用key作为键，df2依然使用index。\n",
    "# 注意：因为指定了df1的key作为键，而df1的key是'K0', 'K1', 'K0', 'K1'。所以df2根据key的值做了两次合并。\n",
    "# 下面这句等价于：pd.merge(left, right, left_on='key', right_index=True, how='left', sort=False);\n",
    "print(df1.join(df2, on = 'key'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 三、连接-concat\n",
    "###### concat参数：\n",
    "###### objs, axis=0, join='outer', join_axes=None, ignore_index=False,keys=None, levels=None, names=None, verify_integrity=False,copy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "0    2\n",
      "1    3\n",
      "2    4\n",
      "3    5\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "0    1\n",
      "0    2\n",
      "1    2\n",
      "1    3\n",
      "2    3\n",
      "2    4\n",
      "3    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ps1 = pd.Series([1,2,3])\n",
    "ps2 = pd.Series([2,3,4,5])\n",
    "print(ps1)\n",
    "print('--------------------------------')\n",
    "print(ps2)\n",
    "print('--------------------------------')\n",
    "# 通过concat将ps1和ps2进行连接。\n",
    "print(pd.concat([ps1,ps2]).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1、参数axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "c    2\n",
      "g    3\n",
      "b    2\n",
      "e    3\n",
      "d    4\n",
      "f    5\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "a    1\n",
      "b    2\n",
      "c    2\n",
      "d    4\n",
      "e    3\n",
      "f    5\n",
      "g    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  NaN  2.0\n",
      "c  2.0  NaN\n",
      "d  NaN  4.0\n",
      "e  NaN  3.0\n",
      "f  NaN  5.0\n",
      "g  3.0  NaN\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# axis默认是0，也就行+行，如果=1那就是列+列\n",
    "ps3 = pd.Series([1,2,3],index = ['a','c','g'])\n",
    "ps4 = pd.Series([2,3,4,5],index = ['b','e','d','f'])\n",
    "print(pd.concat([ps3,ps4]))\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过sort_index里控制是否要对index进行排序。注意与上面的对比。\n",
    "print(pd.concat([ps3,ps4]).sort_index())\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过设置axis=1来设置按列连接，对于空值用NaN来填充。\n",
    "print(pd.concat([ps3,ps4], axis=1))\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B     C     D  key\n",
      "0    A0   B0   NaN   NaN   K0\n",
      "1    A1   B1   NaN   NaN   K1\n",
      "2    A2   B2   NaN   NaN   K0\n",
      "3    A3   B3   NaN   NaN   K1\n",
      "K0  NaN  NaN  C666  D666  NaN\n",
      "K1  NaN  NaN  C777  D777  NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# concat对DataFrame的用法一样\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                     'key': ['K0', 'K1', 'K0', 'K1']})\n",
    "df2 = pd.DataFrame({'C': ['C666', 'C777'],\n",
    "                      'D': ['D666', 'D777']},\n",
    "                     index=['K0', 'K1'])\n",
    "print(pd.concat([df1,df2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2、参数join，join_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  2.0  5.0\n",
      "c  3.0  4.0\n",
      "d  NaN  6.0\n",
      "--------------------------------\n",
      "   0  1\n",
      "b  2  5\n",
      "c  3  4\n",
      "--------------------------------\n",
      "     0    1\n",
      "a  1.0  NaN\n",
      "b  2.0  NaN\n",
      "d  NaN  4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# join\n",
    "ps5 = pd.Series([1,2,3],index = ['a','b','c'])\n",
    "ps6 = pd.Series([4,5,6],index = ['c','b','d'])\n",
    "\n",
    "# 参数join默认是outer,直接进行合并。如果设置成inner则会取交集。\n",
    "print(pd.concat([ps5,ps6], axis= 1, join='outer'))\n",
    "print('--------------------------------')\n",
    "print(pd.concat([ps5,ps6], axis= 1, join='inner'))\n",
    "print('--------------------------------')\n",
    "\n",
    "# 参数join_axes是指定联合的index\n",
    "print(pd.concat([s5,s6], axis = 1, join_axes=[['a','b','d']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3、参数keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "c    4\n",
      "b    5\n",
      "d    6\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "A  a    1\n",
      "   b    2\n",
      "   c    3\n",
      "B  c    4\n",
      "   b    5\n",
      "   d    6\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "('A', 'a')\n",
      "--------------------------------\n",
      "A\n",
      "--------------------------------\n",
      "     A    B\n",
      "a  1.0  NaN\n",
      "b  2.0  5.0\n",
      "c  3.0  4.0\n",
      "d  NaN  6.0\n",
      "--------------------------------\n",
      "Index(['A', 'B'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ps5 = pd.Series([1,2,3],index = ['a','b','c'])\n",
    "ps6 = pd.Series([4,5,6],index = ['c','b','d'])\n",
    "print(ps5)\n",
    "print('--------------------------------')\n",
    "print(ps6)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过参数keys来指定最外层构建层的索引\n",
    "ps7 = pd.concat([ps5, ps6], keys = ['A', 'B'])\n",
    "print('--------------------------------')\n",
    "print(ps7)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过下标方式来访问索引。\n",
    "# 下面得到了两个index，一个是'A'一个'a'\n",
    "print(ps7.index[0])\n",
    "print('--------------------------------')\n",
    "# 得到最外层的索引，'A'。\n",
    "print(ps7.index[0][0])\n",
    "print('--------------------------------')\n",
    "# 如果使用了axis=1这个参数，那么keys的值就是columns。\n",
    "print(pd.concat([ps5, ps6], axis = 1, keys = ['A', 'B']))\n",
    "print('--------------------------------')\n",
    "# 查看一下columns。\n",
    "print(pd.concat([ps5, ps6], axis = 1, keys = ['A', 'B']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 四、修补 combine_first、updata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  NaN  3.0  5.0\n",
      "1  4.0  NaN  NaN\n",
      "2  NaN  6.0  NaN\n",
      "--------------------------------\n",
      "   0     1    2\n",
      "1  7   NaN    8\n",
      "2  9  10.0  666\n",
      "--------------------------------\n",
      "     0    1      2\n",
      "0  NaN  3.0    5.0\n",
      "1  4.0  NaN    8.0\n",
      "2  9.0  6.0  666.0\n",
      "--------------------------------\n",
      "     0     1      2\n",
      "0  NaN   3.0    5.0\n",
      "1  4.0  10.0  666.0\n",
      "2  NaN   6.0    NaN\n",
      "a  7.0   NaN    8.0\n",
      "--------------------------------\n",
      "     0     1      2\n",
      "0  NaN   3.0    5.0\n",
      "1  7.0   NaN    8.0\n",
      "2  9.0  10.0  666.0\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3140: RuntimeWarning: '<' not supported between instances of 'int' and 'str', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame([[np.nan, 3, 5], [4, np.nan, np.nan],[np.nan, 6, np.nan]])\n",
    "df2 = pd.DataFrame([[7, np.nan, 8], [9, 10, 666]],index=[1, 2])\n",
    "print(df1)\n",
    "print('--------------------------------')\n",
    "print(df2)\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过combine_first来讲df2填充到df1里空值的位置上，并且是根据index来做的。\n",
    "print(df1.combine_first(df2))\n",
    "print('--------------------------------')\n",
    "\n",
    "# 如果df3的index比df1的多，那么就直接更新到df1上。\n",
    "df3 = pd.DataFrame([[7, np.nan, 8], [9, 10, 666]],index=['a',1])\n",
    "print(df1.combine_first(df3))\n",
    "print('--------------------------------')\n",
    "\n",
    "# update，根据index的位置，将相同位置的数值用df2直接覆盖df1。\n",
    "df1.update(df2)\n",
    "print(df1)\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 五、去重 duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     2\n",
      "4     2\n",
      "5     2\n",
      "6     1\n",
      "7     2\n",
      "8     3\n",
      "9     3\n",
      "10    3\n",
      "11    4\n",
      "12    4\n",
      "13    4\n",
      "14    5\n",
      "15    5\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "0     False\n",
      "1      True\n",
      "2      True\n",
      "3     False\n",
      "4      True\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8     False\n",
      "9      True\n",
      "10     True\n",
      "11    False\n",
      "12     True\n",
      "13     True\n",
      "14    False\n",
      "15     True\n",
      "dtype: bool\n",
      "--------------------------------\n",
      "0     1\n",
      "3     2\n",
      "8     3\n",
      "11    4\n",
      "14    5\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "通过drop_duplicates直接生成去重后的数据：\n",
      " 0     1\n",
      "3     2\n",
      "8     3\n",
      "11    4\n",
      "14    5\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "0    1\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "4    2\n",
      "5    3\n",
      "6    3\n",
      "7    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "通过drop_duplicates直接生成去重后的数据：\n",
      " 0    1\n",
      "2    2\n",
      "5    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "inplace采用False，不替换原值，所以ps1和原来的ps1是一样的：\n",
      " 0    1\n",
      "1    1\n",
      "2    2\n",
      "3    2\n",
      "4    2\n",
      "5    3\n",
      "6    3\n",
      "7    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "因为inplace=True，所以不生成新的数据，得到的就是None：\n",
      " None\n",
      "--------------------------------\n",
      "inplace采用True，替换原值，所以ps1被修改了！！：\n",
      " 0    1\n",
      "2    2\n",
      "5    3\n",
      "dtype: int64\n",
      "--------------------------------\n",
      "  key1 key2\n",
      "0    a    a\n",
      "1    a    a\n",
      "2    3    b\n",
      "3    4    d\n",
      "4    5    b\n",
      "--------------------------------\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "--------------------------------\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "Name: key2, dtype: bool\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "ps = pd.Series([1,1,1,2,2,2,1,2,3,3,3,4,4,4,5,5])\n",
    "print(ps)\n",
    "print('--------------------------------')\n",
    "# duplicated来判断数据中是否有重复的值，得到是一个布尔型的数据。\n",
    "# 注意：在判断的过程中，对于重复的数据中，出现的第一个是判断为不重复的也就是(False)\n",
    "print(ps.duplicated())\n",
    "print('--------------------------------')\n",
    "\n",
    "# 利用判读出的是否重复的False来得到不重复的值。\n",
    "print(ps[ps.duplicated() == False])\n",
    "print('--------------------------------')\n",
    "\n",
    "# 通过drop_duplicates来直接生成去重后的数据。\n",
    "ps_re = ps.drop_duplicates()\n",
    "print('通过drop_duplicates直接生成去重后的数据：\\n',ps_re)\n",
    "print('--------------------------------')\n",
    "\n",
    "# drop_duplicates有一个inplace参数，表示是否替换原值，默认False。也就不替换原值\n",
    "ps1 = pd.Series([1,1,2,2,2,3,3,3])\n",
    "print(ps1)\n",
    "print('--------------------------------')\n",
    "\n",
    "ps1_re = ps1.drop_duplicates()\n",
    "print('通过drop_duplicates直接生成去重后的数据：\\n',ps1_re)\n",
    "print('--------------------------------')\n",
    "print('inplace采用False，不替换原值，所以ps1和原来的ps1是一样的：\\n',ps1)\n",
    "print('--------------------------------')\n",
    "\n",
    "ps2_re = ps1.drop_duplicates(inplace = True)\n",
    "print('因为inplace=True，所以不生成新的数据，得到的就是None：\\n',ps2_re)\n",
    "print('--------------------------------')\n",
    "print('inplace采用True，替换原值，所以ps1被修改了！！：\\n',ps1)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'key1':['a','a',3,4,5],\n",
    "                  'key2':['a','a','b','d','b']})\n",
    "print(df)\n",
    "print('--------------------------------')\n",
    "\n",
    "# duplicated如果用在DataFrame上的话，是比较两列是否有重复。\n",
    "# 例子中key1列的第一和第二个元素与key2列的第一和第二个元素是重复的，所以结果会出现True。\n",
    "print(df.duplicated())\n",
    "print('--------------------------------')\n",
    "\n",
    "# 如果用只对key2列进行判断，那么就和之前的Series一样了。\n",
    "print(df['key2'].duplicated())\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 六、替换 replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2      b\n",
      "3      b\n",
      "4      c\n",
      "5      c\n",
      "6      d\n",
      "7      d\n",
      "8      e\n",
      "9      e\n",
      "dtype: object\n",
      "--------------------------------\n",
      "0       a\n",
      "1       a\n",
      "2    haha\n",
      "3    haha\n",
      "4    haha\n",
      "5    haha\n",
      "6       d\n",
      "7       d\n",
      "8       e\n",
      "9       e\n",
      "dtype: object\n",
      "--------------------------------\n",
      "0    Python!\n",
      "1    Python!\n",
      "2          b\n",
      "3          b\n",
      "4          c\n",
      "5          c\n",
      "6        666\n",
      "7        666\n",
      "8          e\n",
      "9          e\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(list('aabbccddee'))\n",
    "\n",
    "# 通过replace将list中的a替换成空值。\n",
    "print(s.replace('a', np.nan))\n",
    "print('--------------------------------')\n",
    "\n",
    "# 将list中的b和c替换成haha\n",
    "print(s.replace(['b','c'],'haha'))\n",
    "\n",
    "# 可以通过字典来同时替换多个值，也推荐这样做。\n",
    "print('--------------------------------')\n",
    "print(s.replace({'a':'Python!', 'd':666}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
